
<script type="text/javascript" id="documentation_options" data-url_root="./"
  src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<h1>Source code for pytext.trainers.ensemble_trainer</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">pytext.config</span> <span class="kn">import</span> <span class="n">ConfigBase</span>
<span class="kn">from</span> <span class="nn">pytext.config.component</span> <span class="kn">import</span> <span class="n">create_trainer</span>

<span class="kn">from</span> <span class="nn">.trainer</span> <span class="kn">import</span> <span class="n">TaskTrainer</span><span class="p">,</span> <span class="n">TrainerBase</span>


<span class="k">class</span> <span class="nc">EnsembleTrainer</span><span class="p">(</span><span class="n">TrainerBase</span><span class="p">):</span>
    <span class="sd">"""Trainer for ensemble models</span>

<span class="sd">    Attributes:</span>
<span class="sd">        real_trainer (Trainer): the actual trainer to run</span>
<span class="sd">    """</span>

<div class="viewcode-block" id="EnsembleTrainer.Config"><a class="viewcode-back" href="../../../configs/pytext.trainers.ensemble_trainer.EnsembleTrainer.Config.html#pytext.trainers.ensemble_trainer.EnsembleTrainer.Config">[docs]</a>    <span class="k">class</span> <span class="nc">Config</span><span class="p">(</span><span class="n">ConfigBase</span><span class="p">):</span>
        <span class="n">real_trainer</span><span class="p">:</span> <span class="n">TaskTrainer</span><span class="o">.</span><span class="n">Config</span> <span class="o">=</span> <span class="n">TaskTrainer</span><span class="o">.</span><span class="n">Config</span><span class="p">()</span></div>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Config</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">trainers</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">create_trainer</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">real_trainer</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">models</span>
        <span class="p">]</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">trainers</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">real_trainers</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">real_trainers</span> <span class="o">=</span> <span class="n">real_trainers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">real_trainers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="n">real_trainers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">test</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_single_model</span> <span class="o">=</span> <span class="n">real_trainers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">train</span>

    <span class="sd">"""</span>
<span class="sd">    Train and eval ensemble model, each sub model will be trained separately in</span>
<span class="sd">    sequence, and ``model.merge_sub_models`` will be called to merge states in sub</span>
<span class="sd">    models (e.g transition matrix for crf). To train sub models in parallel, please</span>
<span class="sd">    use train_single_model method instead</span>

<span class="sd">    Args:</span>
<span class="sd">        train_iter (BatchIterator): batch iterator of training data</span>
<span class="sd">        eval_iter (BatchIterator): batch iterator of evaluation data</span>
<span class="sd">        model (Model): model to be trained</span>
<span class="sd">        metric_reporter (MetricReporter): compute metric based on training</span>
<span class="sd">            output and report results to console, file.. etc</span>
<span class="sd">        train_config (PyTextConfig): training config</span>
<span class="sd">        optimizers (List[torch.optim.Optimizer]): a list of torch optimizers, in</span>
<span class="sd">            most of the case only contains one optimizer</span>
<span class="sd">        scheduler (Optional[torch.optim.lr_scheduler]): learning rate scheduler,</span>
<span class="sd">            default is None</span>
<span class="sd">        rank (int): only used in distributed training, the rank of the current</span>
<span class="sd">            training thread, evaluation will only be done in rank 0</span>

<span class="sd">    Returns:</span>
<span class="sd">        model, none: only the trained ensemble model, no best metric will be returned</span>
<span class="sd">            since there's no clear way of aggregating metric from sub models</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">eval_iter</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">models</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">real_trainers</span><span class="p">):</span>
            <span class="n">t</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_iter</span><span class="p">,</span> <span class="n">eval_iter</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">merge_sub_models</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="bp">None</span>
</pre></div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">PyText</a></h1>
<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../train_your_first_model.html">Train your first model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../execute_your_first_model.html">Execute your first model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../visualize_your_model.html">Visualize Model Training with TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pytext_models_in_your_app.html">Use PyText models in your app</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../serving_models_in_production.html">Serve Models in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../config_files.html">Config Files Explained</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../config_commands.html">Config Commands</a></li>
</ul>
<p class="caption"><span class="caption-text">Training More Advanced Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../atis_tutorial.html">Train Intent-Slot model on ATIS Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../hierarchical_intent_slot_tutorial.html">Hierarchical intent and slot filling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../disjoint_multitask_tutorial.html">Multitask training with disjoint datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed_training_tutorial.html">Data Parallel Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../xlm_r.html">XLM-RoBERTa</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending PyText</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../overview.html">Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../datasource_tutorial.html">Custom Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tensorizer.html">Custom Tensorizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dense.html">Using External Dense Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../create_new_model.html">Creating A New Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../hacking_pytext.html">Hacking PyText</a></li>
</ul>
<p class="caption"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../configs/pytext.html">pytext</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/pytext.html">pytext package</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="../../../index.html">Documentation overview</a><ul>
<li><a href="../../index.html">Module code</a><ul>
<li><a href="../../pytext.html">pytext</a><ul>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="../../../search.html" class="search" method="get">
<input aria-labelledby="searchlabel" name="q" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
</div>
</div>
<div class="clearer"></div>
</div></div>