
<script type="text/javascript" id="documentation_options" data-url_root="./"
  src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<div class="section" id="querydocpairwiserankingmodel-config">
<h1>QueryDocPairwiseRankingModel.Config<a class="headerlink" href="#querydocpairwiserankingmodel-config" title="Permalink to this headline">Â¶</a></h1>
<p><strong>Component:</strong> <a class="reference internal" href="../modules/pytext.models.html#pytext.models.query_document_pairwise_ranking_model.QueryDocPairwiseRankingModel" title="pytext.models.query_document_pairwise_ranking_model.QueryDocPairwiseRankingModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QueryDocPairwiseRankingModel</span></code></a></p>
<dl class="class">
<dt>
<em class="property">class </em><code class="sig-prename descclassname">QueryDocPairwiseRankingModel.</code><code class="sig-name descname">Config</code><a class="reference internal" href="../_modules/pytext/models/query_document_pairwise_ranking_model.html#QueryDocPairwiseRankingModel.Config"><span class="viewcode-link">[source]</span></a></dt>
<dd><p><strong>Bases:</strong> <code class="xref py py-class docutils literal notranslate"><span class="pre">PairwiseModel.Config</span></code></p>
</dd></dl>
<p><strong>All Attributes (including base classes)</strong></p>
<blockquote>
<div><dl class="simple">
<dt><strong>inputs</strong>: <a class="reference internal" href="pytext.models.query_document_pairwise_ranking_model.ModelInput.html"><span class="doc">ModelInput</span></a> = <a class="reference internal" href="pytext.models.query_document_pairwise_ranking_model.ModelInput.html"><span class="doc">ModelInput</span></a>()</dt><dd><p></p>
</dd>
<dt><strong>decoder</strong>: <a class="reference internal" href="pytext.models.decoders.mlp_decoder_query_response.MLPDecoderQueryResponse.Config.html"><span class="doc">MLPDecoderQueryResponse.Config</span></a> = <a class="reference internal" href="pytext.models.decoders.mlp_decoder_query_response.MLPDecoderQueryResponse.Config.html"><span class="doc">MLPDecoderQueryResponse.Config</span></a>()</dt><dd><p></p>
</dd>
<dt><strong>output_layer</strong>: <a class="reference internal" href="pytext.models.output_layers.pairwise_ranking_output_layer.PairwiseRankingOutputLayer.Config.html"><span class="doc">PairwiseRankingOutputLayer.Config</span></a> = <a class="reference internal" href="pytext.models.output_layers.pairwise_ranking_output_layer.PairwiseRankingOutputLayer.Config.html"><span class="doc">PairwiseRankingOutputLayer.Config</span></a>()</dt><dd><p></p>
</dd>
<dt><strong>encode_relations</strong>: bool = <code class="docutils literal notranslate"><span class="pre">True</span></code></dt><dd><p></p>
</dd>
<dt><strong>embedding</strong>: <a class="reference internal" href="pytext.models.embeddings.word_embedding.WordEmbedding.Config.html"><span class="doc">WordEmbedding.Config</span></a> = <a class="reference internal" href="pytext.models.embeddings.word_embedding.WordEmbedding.Config.html"><span class="doc">WordEmbedding.Config</span></a>()</dt><dd><p></p>
</dd>
<dt><strong>representation</strong>: Union[<a class="reference internal" href="pytext.models.representations.bilstm_doc_attention.BiLSTMDocAttention.Config.html"><span class="doc">BiLSTMDocAttention.Config</span></a>, <a class="reference internal" href="pytext.models.representations.docnn.DocNNRepresentation.Config.html"><span class="doc">DocNNRepresentation.Config</span></a>] = <a class="reference internal" href="pytext.models.representations.bilstm_doc_attention.BiLSTMDocAttention.Config.html"><span class="doc">BiLSTMDocAttention.Config</span></a>()</dt><dd><p></p>
</dd>
<dt><strong>shared_representations</strong>: bool = <code class="docutils literal notranslate"><span class="pre">True</span></code></dt><dd><p></p>
</dd>
<dt><strong>decoder_output_dim</strong>: int = <code class="docutils literal notranslate"><span class="pre">64</span></code></dt><dd><p></p>
</dd>
</dl>
</div></blockquote>
<p><strong>Default JSON</strong></p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">"inputs"</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">"pos_response"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"is_input"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
            <span class="nt">"column"</span><span class="p">:</span> <span class="s2">"pos_response"</span><span class="p">,</span>
            <span class="nt">"tokenizer"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"Tokenizer"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="nt">"split_regex"</span><span class="p">:</span> <span class="s2">"\\s+"</span><span class="p">,</span>
                    <span class="nt">"lowercase"</span><span class="p">:</span> <span class="kc">true</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="nt">"add_bos_token"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"add_eos_token"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"use_eos_token_for_bos"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"max_seq_len"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"vocab"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"build_from_data"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
                <span class="nt">"size_from_data"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="nt">"vocab_files"</span><span class="p">:</span> <span class="p">[]</span>
            <span class="p">},</span>
            <span class="nt">"vocab_file_delimiter"</span><span class="p">:</span> <span class="s2">" "</span>
        <span class="p">},</span>
        <span class="nt">"neg_response"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"is_input"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
            <span class="nt">"column"</span><span class="p">:</span> <span class="s2">"neg_response"</span><span class="p">,</span>
            <span class="nt">"tokenizer"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"Tokenizer"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="nt">"split_regex"</span><span class="p">:</span> <span class="s2">"\\s+"</span><span class="p">,</span>
                    <span class="nt">"lowercase"</span><span class="p">:</span> <span class="kc">true</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="nt">"add_bos_token"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"add_eos_token"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"use_eos_token_for_bos"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"max_seq_len"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"vocab"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"build_from_data"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
                <span class="nt">"size_from_data"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="nt">"vocab_files"</span><span class="p">:</span> <span class="p">[]</span>
            <span class="p">},</span>
            <span class="nt">"vocab_file_delimiter"</span><span class="p">:</span> <span class="s2">" "</span>
        <span class="p">},</span>
        <span class="nt">"query"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"is_input"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
            <span class="nt">"column"</span><span class="p">:</span> <span class="s2">"query"</span><span class="p">,</span>
            <span class="nt">"tokenizer"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"Tokenizer"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="nt">"split_regex"</span><span class="p">:</span> <span class="s2">"\\s+"</span><span class="p">,</span>
                    <span class="nt">"lowercase"</span><span class="p">:</span> <span class="kc">true</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="nt">"add_bos_token"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"add_eos_token"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"use_eos_token_for_bos"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"max_seq_len"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"vocab"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"build_from_data"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
                <span class="nt">"size_from_data"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="nt">"vocab_files"</span><span class="p">:</span> <span class="p">[]</span>
            <span class="p">},</span>
            <span class="nt">"vocab_file_delimiter"</span><span class="p">:</span> <span class="s2">" "</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="nt">"decoder"</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"hidden_dims"</span><span class="p">:</span> <span class="p">[]</span>
    <span class="p">},</span>
    <span class="nt">"output_layer"</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"loss"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"margin"</span><span class="p">:</span> <span class="mf">1.0</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="nt">"encode_relations"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
    <span class="nt">"embedding"</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"embed_dim"</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
        <span class="nt">"embedding_init_strategy"</span><span class="p">:</span> <span class="s2">"random"</span><span class="p">,</span>
        <span class="nt">"embedding_init_range"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"export_input_names"</span><span class="p">:</span> <span class="p">[</span>
            <span class="s2">"tokens_vals"</span>
        <span class="p">],</span>
        <span class="nt">"pretrained_embeddings_path"</span><span class="p">:</span> <span class="s2">""</span><span class="p">,</span>
        <span class="nt">"vocab_file"</span><span class="p">:</span> <span class="s2">""</span><span class="p">,</span>
        <span class="nt">"vocab_size"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">"vocab_from_train_data"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">"vocab_from_all_data"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"vocab_from_pretrained_embeddings"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"lowercase_tokens"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">"min_freq"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="nt">"mlp_layer_dims"</span><span class="p">:</span> <span class="p">[],</span>
        <span class="nt">"padding_idx"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"cpu_only"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"skip_header"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">"delimiter"</span><span class="p">:</span> <span class="s2">" "</span>
    <span class="p">},</span>
    <span class="nt">"representation"</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">"BiLSTMDocAttention"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"dropout"</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span>
            <span class="nt">"lstm"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
                <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
                <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
                <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
                <span class="nt">"dropout"</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span>
                <span class="nt">"lstm_dim"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
                <span class="nt">"num_layers"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                <span class="nt">"bidirectional"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
                <span class="nt">"pack_sequence"</span><span class="p">:</span> <span class="kc">true</span>
            <span class="p">},</span>
            <span class="nt">"pooling"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"SelfAttention"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="nt">"attn_dimension"</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
                    <span class="nt">"dropout"</span><span class="p">:</span> <span class="mf">0.4</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="nt">"mlp_decoder"</span><span class="p">:</span> <span class="kc">null</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="nt">"shared_representations"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
    <span class="nt">"decoder_output_dim"</span><span class="p">:</span> <span class="mi">64</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">PyText</a></h1>
<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../train_your_first_model.html">Train your first model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../execute_your_first_model.html">Execute your first model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../visualize_your_model.html">Visualize Model Training with TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pytext_models_in_your_app.html">Use PyText models in your app</a></li>
<li class="toctree-l1"><a class="reference internal" href="../serving_models_in_production.html">Serve Models in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../config_files.html">Config Files Explained</a></li>
<li class="toctree-l1"><a class="reference internal" href="../config_commands.html">Config Commands</a></li>
</ul>
<p class="caption"><span class="caption-text">Training More Advanced Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../atis_tutorial.html">Train Intent-Slot model on ATIS Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hierarchical_intent_slot_tutorial.html">Hierarchical intent and slot filling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../disjoint_multitask_tutorial.html">Multitask training with disjoint datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed_training_tutorial.html">Data Parallel Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../xlm_r.html">XLM-RoBERTa</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending PyText</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasource_tutorial.html">Custom Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensorizer.html">Custom Tensorizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dense.html">Using External Dense Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../create_new_model.html">Creating A New Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hacking_pytext.html">Hacking PyText</a></li>
</ul>
<p class="caption"><span class="caption-text">References</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="pytext.html">pytext</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="pytext.config.html">config</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.data.html">data</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.exporters.html">exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.loss.html">loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.metric_reporters.html">metric_reporters</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="pytext.models.html">models</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.optimizer.html">optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.task.html">task</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.trainers.html">trainers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules/pytext.html">pytext package</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="../index.html">Documentation overview</a><ul>
<li><a href="pytext.html">pytext</a><ul>
<li><a href="pytext.models.html">models</a><ul>
<li><a href="pytext.models.query_document_pairwise_ranking_model.html">query_document_pairwise_ranking_model</a><ul>
<li>Previous: <a href="pytext.models.query_document_pairwise_ranking_model.ModelInput.html" title="previous chapter">ModelInput</a></li>
<li>Next: <a href="pytext.models.representations.html" title="next chapter">representations</a></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="../search.html" class="search" method="get">
<input aria-labelledby="searchlabel" name="q" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
</div>
</div>
<div class="clearer"></div>
</div></div>