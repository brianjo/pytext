
<script type="text/javascript" id="documentation_options" data-url_root="./"
  src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<div class="section" id="wordtagginglitemodel-config">
<h1>WordTaggingLiteModel.Config<a class="headerlink" href="#wordtagginglitemodel-config" title="Permalink to this headline">Â¶</a></h1>
<p><strong>Component:</strong> <a class="reference internal" href="../modules/pytext.models.html#pytext.models.word_model.WordTaggingLiteModel" title="pytext.models.word_model.WordTaggingLiteModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">WordTaggingLiteModel</span></code></a></p>
<dl class="class">
<dt>
<em class="property">class </em><code class="sig-prename descclassname">WordTaggingLiteModel.</code><code class="sig-name descname">Config</code><a class="reference internal" href="../_modules/pytext/models/word_model.html#WordTaggingLiteModel.Config"><span class="viewcode-link">[source]</span></a></dt>
<dd><p><strong>Bases:</strong> <code class="xref py py-class docutils literal notranslate"><span class="pre">WordTaggingModel.Config</span></code></p>
</dd></dl>
<p><strong>All Attributes (including base classes)</strong></p>
<blockquote>
<div><dl class="simple">
<dt><strong>inputs</strong>: <a class="reference internal" href="pytext.models.word_model.ByteModelInput.html"><span class="doc">ByteModelInput</span></a> = <a class="reference internal" href="pytext.models.word_model.ByteModelInput.html"><span class="doc">ByteModelInput</span></a>()</dt><dd><p></p>
</dd>
<dt><strong>embedding</strong>: <a class="reference internal" href="pytext.models.embeddings.char_embedding.CharacterEmbedding.Config.html"><span class="doc">CharacterEmbedding.Config</span></a> = <a class="reference internal" href="pytext.models.embeddings.char_embedding.CharacterEmbedding.Config.html"><span class="doc">CharacterEmbedding.Config</span></a>()</dt><dd><p></p>
</dd>
<dt><strong>representation</strong>: Union[<a class="reference internal" href="pytext.models.representations.bilstm_slot_attn.BiLSTMSlotAttention.Config.html"><span class="doc">BiLSTMSlotAttention.Config</span></a>, <a class="reference internal" href="pytext.models.representations.biseqcnn.BSeqCNNRepresentation.Config.html"><span class="doc">BSeqCNNRepresentation.Config</span></a>, <a class="reference internal" href="pytext.models.representations.pass_through.PassThroughRepresentation.Config.html"><span class="doc">PassThroughRepresentation.Config</span></a>, <a class="reference internal" href="pytext.models.representations.deepcnn.DeepCNNRepresentation.Config.html"><span class="doc">DeepCNNRepresentation.Config</span></a>] = <a class="reference internal" href="pytext.models.representations.pass_through.PassThroughRepresentation.Config.html"><span class="doc">PassThroughRepresentation.Config</span></a>()</dt><dd><p></p>
</dd>
<dt><strong>output_layer</strong>: Union[<a class="reference internal" href="pytext.models.output_layers.word_tagging_output_layer.WordTaggingOutputLayer.Config.html"><span class="doc">WordTaggingOutputLayer.Config</span></a>, <a class="reference internal" href="pytext.models.output_layers.word_tagging_output_layer.CRFOutputLayer.Config.html"><span class="doc">CRFOutputLayer.Config</span></a>] = <a class="reference internal" href="pytext.models.output_layers.word_tagging_output_layer.WordTaggingOutputLayer.Config.html"><span class="doc">WordTaggingOutputLayer.Config</span></a>()</dt><dd><p></p>
</dd>
<dt><strong>decoder</strong>: <a class="reference internal" href="pytext.models.decoders.mlp_decoder.MLPDecoder.Config.html"><span class="doc">MLPDecoder.Config</span></a> = <a class="reference internal" href="pytext.models.decoders.mlp_decoder.MLPDecoder.Config.html"><span class="doc">MLPDecoder.Config</span></a>()</dt><dd><p></p>
</dd>
</dl>
</div></blockquote>
<p><strong>Default JSON</strong></p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">"inputs"</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">"token_bytes"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"is_input"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
            <span class="nt">"column"</span><span class="p">:</span> <span class="s2">"text"</span><span class="p">,</span>
            <span class="nt">"tokenizer"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"Tokenizer"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="nt">"split_regex"</span><span class="p">:</span> <span class="s2">"\\s+"</span><span class="p">,</span>
                    <span class="nt">"lowercase"</span><span class="p">:</span> <span class="kc">true</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="nt">"max_seq_len"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"max_byte_len"</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span>
            <span class="nt">"offset_for_non_padding"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="nt">"add_bos_token"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"add_eos_token"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"use_eos_token_for_bos"</span><span class="p">:</span> <span class="kc">false</span>
        <span class="p">},</span>
        <span class="nt">"labels"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"is_input"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"slot_column"</span><span class="p">:</span> <span class="s2">"slots"</span><span class="p">,</span>
            <span class="nt">"text_column"</span><span class="p">:</span> <span class="s2">"text"</span><span class="p">,</span>
            <span class="nt">"tokenizer"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"Tokenizer"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="nt">"split_regex"</span><span class="p">:</span> <span class="s2">"\\s+"</span><span class="p">,</span>
                    <span class="nt">"lowercase"</span><span class="p">:</span> <span class="kc">true</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="nt">"allow_unknown"</span><span class="p">:</span> <span class="kc">false</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="nt">"embedding"</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"embed_dim"</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
        <span class="nt">"sparse"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"cnn"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"kernel_num"</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
            <span class="nt">"kernel_sizes"</span><span class="p">:</span> <span class="p">[</span>
                <span class="mi">3</span><span class="p">,</span>
                <span class="mi">4</span>
            <span class="p">],</span>
            <span class="nt">"weight_norm"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"dilated"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"causal"</span><span class="p">:</span> <span class="kc">false</span>
        <span class="p">},</span>
        <span class="nt">"highway_layers"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">"projection_dim"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"export_input_names"</span><span class="p">:</span> <span class="p">[</span>
            <span class="s2">"char_vals"</span>
        <span class="p">],</span>
        <span class="nt">"vocab_from_train_data"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">"max_word_length"</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
        <span class="nt">"min_freq"</span><span class="p">:</span> <span class="mi">1</span>
    <span class="p">},</span>
    <span class="nt">"representation"</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">"PassThroughRepresentation"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="nt">"output_layer"</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">"WordTaggingOutputLayer"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"loss"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"CrossEntropyLoss"</span><span class="p">:</span> <span class="p">{}</span>
            <span class="p">},</span>
            <span class="nt">"label_weights"</span><span class="p">:</span> <span class="p">{},</span>
            <span class="nt">"ignore_pad_in_loss"</span><span class="p">:</span> <span class="kc">true</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="nt">"decoder"</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"hidden_dims"</span><span class="p">:</span> <span class="p">[],</span>
        <span class="nt">"out_dim"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"layer_norm"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"dropout"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="nt">"activation"</span><span class="p">:</span> <span class="s2">"relu"</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">PyText</a></h1>
<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../train_your_first_model.html">Train your first model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../execute_your_first_model.html">Execute your first model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../visualize_your_model.html">Visualize Model Training with TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pytext_models_in_your_app.html">Use PyText models in your app</a></li>
<li class="toctree-l1"><a class="reference internal" href="../serving_models_in_production.html">Serve Models in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../config_files.html">Config Files Explained</a></li>
<li class="toctree-l1"><a class="reference internal" href="../config_commands.html">Config Commands</a></li>
</ul>
<p class="caption"><span class="caption-text">Training More Advanced Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../atis_tutorial.html">Train Intent-Slot model on ATIS Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hierarchical_intent_slot_tutorial.html">Hierarchical intent and slot filling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../disjoint_multitask_tutorial.html">Multitask training with disjoint datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed_training_tutorial.html">Data Parallel Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../xlm_r.html">XLM-RoBERTa</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending PyText</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasource_tutorial.html">Custom Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensorizer.html">Custom Tensorizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dense.html">Using External Dense Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../create_new_model.html">Creating A New Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hacking_pytext.html">Hacking PyText</a></li>
</ul>
<p class="caption"><span class="caption-text">References</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="pytext.html">pytext</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="pytext.config.html">config</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.data.html">data</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.exporters.html">exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.loss.html">loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.metric_reporters.html">metric_reporters</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="pytext.models.html">models</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.optimizer.html">optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.task.html">task</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.trainers.html">trainers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules/pytext.html">pytext package</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="../index.html">Documentation overview</a><ul>
<li><a href="pytext.html">pytext</a><ul>
<li><a href="pytext.models.html">models</a><ul>
<li><a href="pytext.models.word_model.html">word_model</a><ul>
<li>Previous: <a href="pytext.models.word_model.ModelInput.html" title="previous chapter">ModelInput</a></li>
<li>Next: <a href="pytext.models.word_model.WordTaggingModel.Config.html" title="next chapter">WordTaggingModel.Config</a></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="../search.html" class="search" method="get">
<input aria-labelledby="searchlabel" name="q" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
</div>
</div>
<div class="clearer"></div>
</div></div>