
<script type="text/javascript" id="documentation_options" data-url_root="./"
  src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<div class="section" id="intentslotmodel-config">
<h1>IntentSlotModel.Config<a class="headerlink" href="#intentslotmodel-config" title="Permalink to this headline">Â¶</a></h1>
<p><strong>Component:</strong> <a class="reference internal" href="../modules/pytext.models.html#pytext.models.joint_model.IntentSlotModel" title="pytext.models.joint_model.IntentSlotModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">IntentSlotModel</span></code></a></p>
<dl class="class">
<dt>
<em class="property">class </em><code class="sig-prename descclassname">IntentSlotModel.</code><code class="sig-name descname">Config</code><a class="reference internal" href="../_modules/pytext/models/joint_model.html#IntentSlotModel.Config"><span class="viewcode-link">[source]</span></a></dt>
<dd><p><strong>Bases:</strong> <code class="xref py py-class docutils literal notranslate"><span class="pre">Model.Config</span></code></p>
</dd></dl>
<p><strong>All Attributes (including base classes)</strong></p>
<blockquote>
<div><dl class="simple">
<dt><strong>inputs</strong>: <a class="reference internal" href="pytext.models.joint_model.ModelInput.html"><span class="doc">ModelInput</span></a> = <a class="reference internal" href="pytext.models.joint_model.ModelInput.html"><span class="doc">ModelInput</span></a>()</dt><dd><p></p>
</dd>
<dt><strong>word_embedding</strong>: <a class="reference internal" href="pytext.models.embeddings.word_embedding.WordEmbedding.Config.html"><span class="doc">WordEmbedding.Config</span></a> = <a class="reference internal" href="pytext.models.embeddings.word_embedding.WordEmbedding.Config.html"><span class="doc">WordEmbedding.Config</span></a>()</dt><dd><p></p>
</dd>
<dt><strong>representation</strong>: Union[<a class="reference internal" href="pytext.models.representations.bilstm_doc_slot_attention.BiLSTMDocSlotAttention.Config.html"><span class="doc">BiLSTMDocSlotAttention.Config</span></a>, <a class="reference internal" href="pytext.models.representations.jointcnn_rep.JointCNNRepresentation.Config.html"><span class="doc">JointCNNRepresentation.Config</span></a>, <a class="reference internal" href="pytext.models.representations.jointcnn_rep.SharedCNNRepresentation.Config.html"><span class="doc">SharedCNNRepresentation.Config</span></a>, <a class="reference internal" href="pytext.models.representations.pass_through.PassThroughRepresentation.Config.html"><span class="doc">PassThroughRepresentation.Config</span></a>] = <a class="reference internal" href="pytext.models.representations.bilstm_doc_slot_attention.BiLSTMDocSlotAttention.Config.html"><span class="doc">BiLSTMDocSlotAttention.Config</span></a>()</dt><dd><p></p>
</dd>
<dt><strong>output_layer</strong>: <a class="reference internal" href="pytext.models.output_layers.intent_slot_output_layer.IntentSlotOutputLayer.Config.html"><span class="doc">IntentSlotOutputLayer.Config</span></a> = <a class="reference internal" href="pytext.models.output_layers.intent_slot_output_layer.IntentSlotOutputLayer.Config.html"><span class="doc">IntentSlotOutputLayer.Config</span></a>()</dt><dd><p></p>
</dd>
<dt><strong>decoder</strong>: <a class="reference internal" href="pytext.models.decoders.intent_slot_model_decoder.IntentSlotModelDecoder.Config.html"><span class="doc">IntentSlotModelDecoder.Config</span></a> = <a class="reference internal" href="pytext.models.decoders.intent_slot_model_decoder.IntentSlotModelDecoder.Config.html"><span class="doc">IntentSlotModelDecoder.Config</span></a>()</dt><dd><p></p>
</dd>
<dt><strong>default_doc_loss_weight</strong>: float = <code class="docutils literal notranslate"><span class="pre">0.2</span></code></dt><dd><p></p>
</dd>
<dt><strong>default_word_loss_weight</strong>: float = <code class="docutils literal notranslate"><span class="pre">0.5</span></code></dt><dd><p></p>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt><strong>Subclasses</strong></dt><dd><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">ContextualIntentSlotModel.Config</span></code></p></li>
</ul>
</dd>
</dl>
<p><strong>Default JSON</strong></p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">"inputs"</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">"tokens"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"is_input"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
            <span class="nt">"column"</span><span class="p">:</span> <span class="s2">"text"</span><span class="p">,</span>
            <span class="nt">"tokenizer"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"Tokenizer"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="nt">"split_regex"</span><span class="p">:</span> <span class="s2">"\\s+"</span><span class="p">,</span>
                    <span class="nt">"lowercase"</span><span class="p">:</span> <span class="kc">true</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="nt">"add_bos_token"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"add_eos_token"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"use_eos_token_for_bos"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"max_seq_len"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"vocab"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"build_from_data"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
                <span class="nt">"size_from_data"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="nt">"vocab_files"</span><span class="p">:</span> <span class="p">[]</span>
            <span class="p">},</span>
            <span class="nt">"vocab_file_delimiter"</span><span class="p">:</span> <span class="s2">" "</span>
        <span class="p">},</span>
        <span class="nt">"word_labels"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"is_input"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"slot_column"</span><span class="p">:</span> <span class="s2">"slots"</span><span class="p">,</span>
            <span class="nt">"text_column"</span><span class="p">:</span> <span class="s2">"text"</span><span class="p">,</span>
            <span class="nt">"tokenizer"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"Tokenizer"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="nt">"split_regex"</span><span class="p">:</span> <span class="s2">"\\s+"</span><span class="p">,</span>
                    <span class="nt">"lowercase"</span><span class="p">:</span> <span class="kc">true</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="nt">"allow_unknown"</span><span class="p">:</span> <span class="kc">true</span>
        <span class="p">},</span>
        <span class="nt">"doc_labels"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"LabelTensorizer"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"is_input"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
                <span class="nt">"column"</span><span class="p">:</span> <span class="s2">"label"</span><span class="p">,</span>
                <span class="nt">"allow_unknown"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
                <span class="nt">"pad_in_vocab"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
                <span class="nt">"label_vocab"</span><span class="p">:</span> <span class="kc">null</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="nt">"doc_weight"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"word_weight"</span><span class="p">:</span> <span class="kc">null</span>
    <span class="p">},</span>
    <span class="nt">"word_embedding"</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"embed_dim"</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
        <span class="nt">"embedding_init_strategy"</span><span class="p">:</span> <span class="s2">"random"</span><span class="p">,</span>
        <span class="nt">"embedding_init_range"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"export_input_names"</span><span class="p">:</span> <span class="p">[</span>
            <span class="s2">"tokens_vals"</span>
        <span class="p">],</span>
        <span class="nt">"pretrained_embeddings_path"</span><span class="p">:</span> <span class="s2">""</span><span class="p">,</span>
        <span class="nt">"vocab_file"</span><span class="p">:</span> <span class="s2">""</span><span class="p">,</span>
        <span class="nt">"vocab_size"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">"vocab_from_train_data"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">"vocab_from_all_data"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"vocab_from_pretrained_embeddings"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"lowercase_tokens"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">"min_freq"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="nt">"mlp_layer_dims"</span><span class="p">:</span> <span class="p">[],</span>
        <span class="nt">"padding_idx"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"cpu_only"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"skip_header"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">"delimiter"</span><span class="p">:</span> <span class="s2">" "</span>
    <span class="p">},</span>
    <span class="nt">"representation"</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">"BiLSTMDocSlotAttention"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"dropout"</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span>
            <span class="nt">"lstm"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"BiLSTM"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
                    <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
                    <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
                    <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
                    <span class="nt">"dropout"</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span>
                    <span class="nt">"lstm_dim"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
                    <span class="nt">"num_layers"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                    <span class="nt">"bidirectional"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
                    <span class="nt">"pack_sequence"</span><span class="p">:</span> <span class="kc">true</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="nt">"pooling"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"slot_attention"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"doc_mlp_layers"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="nt">"word_mlp_layers"</span><span class="p">:</span> <span class="mi">0</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="nt">"output_layer"</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"doc_output"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"loss"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"CrossEntropyLoss"</span><span class="p">:</span> <span class="p">{}</span>
            <span class="p">},</span>
            <span class="nt">"label_weights"</span><span class="p">:</span> <span class="kc">null</span>
        <span class="p">},</span>
        <span class="nt">"word_output"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"WordTaggingOutputLayer"</span><span class="p">:</span> <span class="p">{</span>
                <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
                <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
                <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
                <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
                <span class="nt">"loss"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="nt">"CrossEntropyLoss"</span><span class="p">:</span> <span class="p">{}</span>
                <span class="p">},</span>
                <span class="nt">"label_weights"</span><span class="p">:</span> <span class="p">{},</span>
                <span class="nt">"ignore_pad_in_loss"</span><span class="p">:</span> <span class="kc">true</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="nt">"decoder"</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
        <span class="nt">"use_doc_probs_in_word"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="nt">"doc_decoder"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"hidden_dims"</span><span class="p">:</span> <span class="p">[],</span>
            <span class="nt">"out_dim"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"layer_norm"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"dropout"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
            <span class="nt">"activation"</span><span class="p">:</span> <span class="s2">"relu"</span>
        <span class="p">},</span>
        <span class="nt">"word_decoder"</span><span class="p">:</span> <span class="p">{</span>
            <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"hidden_dims"</span><span class="p">:</span> <span class="p">[],</span>
            <span class="nt">"out_dim"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
            <span class="nt">"layer_norm"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
            <span class="nt">"dropout"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
            <span class="nt">"activation"</span><span class="p">:</span> <span class="s2">"relu"</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="nt">"default_doc_loss_weight"</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span>
    <span class="nt">"default_word_loss_weight"</span><span class="p">:</span> <span class="mf">0.5</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">PyText</a></h1>
<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../train_your_first_model.html">Train your first model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../execute_your_first_model.html">Execute your first model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../visualize_your_model.html">Visualize Model Training with TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pytext_models_in_your_app.html">Use PyText models in your app</a></li>
<li class="toctree-l1"><a class="reference internal" href="../serving_models_in_production.html">Serve Models in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../config_files.html">Config Files Explained</a></li>
<li class="toctree-l1"><a class="reference internal" href="../config_commands.html">Config Commands</a></li>
</ul>
<p class="caption"><span class="caption-text">Training More Advanced Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../atis_tutorial.html">Train Intent-Slot model on ATIS Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hierarchical_intent_slot_tutorial.html">Hierarchical intent and slot filling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../disjoint_multitask_tutorial.html">Multitask training with disjoint datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed_training_tutorial.html">Data Parallel Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../xlm_r.html">XLM-RoBERTa</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending PyText</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasource_tutorial.html">Custom Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensorizer.html">Custom Tensorizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dense.html">Using External Dense Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../create_new_model.html">Creating A New Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hacking_pytext.html">Hacking PyText</a></li>
</ul>
<p class="caption"><span class="caption-text">References</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="pytext.html">pytext</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="pytext.config.html">config</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.data.html">data</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.exporters.html">exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.loss.html">loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.metric_reporters.html">metric_reporters</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="pytext.models.html">models</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.optimizer.html">optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.task.html">task</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.trainers.html">trainers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules/pytext.html">pytext package</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="../index.html">Documentation overview</a><ul>
<li><a href="pytext.html">pytext</a><ul>
<li><a href="pytext.models.html">models</a><ul>
<li><a href="pytext.models.joint_model.html">joint_model</a><ul>
<li>Previous: <a href="pytext.models.joint_model.html" title="previous chapter">joint_model</a></li>
<li>Next: <a href="pytext.models.joint_model.ModelInput.html" title="next chapter">ModelInput</a></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="../search.html" class="search" method="get">
<input aria-labelledby="searchlabel" name="q" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
</div>
</div>
<div class="clearer"></div>
</div></div>