
<script type="text/javascript" id="documentation_options" data-url_root="./"
  src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<div class="section" id="sparsetransformersentenceencoder-config">
<h1>SparseTransformerSentenceEncoder.Config<a class="headerlink" href="#sparsetransformersentenceencoder-config" title="Permalink to this headline">Â¶</a></h1>
<p><strong>Component:</strong> <a class="reference internal" href="../modules/pytext.models.representations.html#pytext.models.representations.sparse_transformer_sentence_encoder.SparseTransformerSentenceEncoder" title="pytext.models.representations.sparse_transformer_sentence_encoder.SparseTransformerSentenceEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">SparseTransformerSentenceEncoder</span></code></a></p>
<dl class="class">
<dt>
<em class="property">class </em><code class="sig-prename descclassname">SparseTransformerSentenceEncoder.</code><code class="sig-name descname">Config</code><a class="reference internal" href="../_modules/pytext/models/representations/sparse_transformer_sentence_encoder.html#SparseTransformerSentenceEncoder.Config"><span class="viewcode-link">[source]</span></a></dt>
<dd><p><strong>Bases:</strong> <code class="xref py py-class docutils literal notranslate"><span class="pre">TransformerSentenceEncoder.Config</span></code>, <a class="reference internal" href="../modules/pytext.config.html#pytext.config.pytext_config.ConfigBase" title="pytext.config.pytext_config.ConfigBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConfigBase</span></code></a></p>
</dd></dl>
<p><strong>All Attributes (including base classes)</strong></p>
<blockquote>
<div><dl class="simple">
<dt><strong>load_path</strong>: Optional[str] = <code class="docutils literal notranslate"><span class="pre">None</span></code></dt><dd><p></p>
</dd>
<dt><strong>save_path</strong>: Optional[str] = <code class="docutils literal notranslate"><span class="pre">None</span></code></dt><dd><p></p>
</dd>
<dt><strong>freeze</strong>: bool = <code class="docutils literal notranslate"><span class="pre">False</span></code></dt><dd><p></p>
</dd>
<dt><strong>shared_module_key</strong>: Optional[str] = <code class="docutils literal notranslate"><span class="pre">None</span></code></dt><dd><p></p>
</dd>
<dt><strong>output_dropout</strong>: float = <code class="docutils literal notranslate"><span class="pre">0.4</span></code></dt><dd><p></p>
</dd>
<dt><strong>embedding_dim</strong>: int = <code class="docutils literal notranslate"><span class="pre">768</span></code></dt><dd><p></p>
</dd>
<dt><strong>pooling</strong>: PoolingMethod = <code class="docutils literal notranslate"><span class="pre">&lt;PoolingMethod.CLS_TOKEN:</span> <span class="pre">'cls_token'&gt;</span></code></dt><dd><p></p>
</dd>
<dt><strong>export</strong>: bool = <code class="docutils literal notranslate"><span class="pre">False</span></code></dt><dd><p></p>
</dd>
<dt><strong>dropout</strong>: float = <code class="docutils literal notranslate"><span class="pre">0.1</span></code></dt><dd><p></p>
</dd>
<dt><strong>attention_dropout</strong>: float = <code class="docutils literal notranslate"><span class="pre">0.1</span></code></dt><dd><p></p>
</dd>
<dt><strong>activation_dropout</strong>: float = <code class="docutils literal notranslate"><span class="pre">0.1</span></code></dt><dd><p></p>
</dd>
<dt><strong>ffn_embedding_dim</strong>: int = <code class="docutils literal notranslate"><span class="pre">3072</span></code></dt><dd><p></p>
</dd>
<dt><strong>num_encoder_layers</strong>: int = <code class="docutils literal notranslate"><span class="pre">6</span></code></dt><dd><p></p>
</dd>
<dt><strong>num_attention_heads</strong>: int = <code class="docutils literal notranslate"><span class="pre">8</span></code></dt><dd><p></p>
</dd>
<dt><strong>num_segments</strong>: int = <code class="docutils literal notranslate"><span class="pre">2</span></code></dt><dd><p></p>
</dd>
<dt><strong>use_position_embeddings</strong>: bool = <code class="docutils literal notranslate"><span class="pre">True</span></code></dt><dd><p></p>
</dd>
<dt><strong>offset_positions_by_padding</strong>: bool = <code class="docutils literal notranslate"><span class="pre">True</span></code></dt><dd><p></p>
</dd>
<dt><strong>apply_bert_init</strong>: bool = <code class="docutils literal notranslate"><span class="pre">True</span></code></dt><dd><p></p>
</dd>
<dt><strong>encoder_normalize_before</strong>: bool = <code class="docutils literal notranslate"><span class="pre">True</span></code></dt><dd><p></p>
</dd>
<dt><strong>activation_fn</strong>: str = <code class="docutils literal notranslate"><span class="pre">'relu'</span></code></dt><dd><p></p>
</dd>
<dt><strong>projection_dim</strong>: int = <code class="docutils literal notranslate"><span class="pre">0</span></code></dt><dd><p></p>
</dd>
<dt><strong>max_seq_len</strong>: int = <code class="docutils literal notranslate"><span class="pre">128</span></code></dt><dd><p></p>
</dd>
<dt><strong>multilingual</strong>: bool = <code class="docutils literal notranslate"><span class="pre">False</span></code></dt><dd><p></p>
</dd>
<dt><strong>freeze_embeddings</strong>: bool = <code class="docutils literal notranslate"><span class="pre">False</span></code></dt><dd><p></p>
</dd>
<dt><strong>n_trans_layers_to_freeze</strong>: int = <code class="docutils literal notranslate"><span class="pre">0</span></code></dt><dd><p></p>
</dd>
<dt><strong>use_torchscript</strong>: bool = <code class="docutils literal notranslate"><span class="pre">False</span></code></dt><dd><p></p>
</dd>
<dt><strong>project_representation</strong>: bool = <code class="docutils literal notranslate"><span class="pre">False</span></code></dt><dd><p></p>
</dd>
<dt><strong>is_bidirectional</strong>: bool = <code class="docutils literal notranslate"><span class="pre">True</span></code></dt><dd><p></p>
</dd>
<dt><strong>stride</strong>: int = <code class="docutils literal notranslate"><span class="pre">32</span></code></dt><dd><p></p>
</dd>
<dt><strong>expressivity</strong>: int = <code class="docutils literal notranslate"><span class="pre">8</span></code></dt><dd><p></p>
</dd>
</dl>
</div></blockquote>
<p><strong>Default JSON</strong></p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">"load_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
    <span class="nt">"save_path"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
    <span class="nt">"freeze"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
    <span class="nt">"shared_module_key"</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
    <span class="nt">"output_dropout"</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span>
    <span class="nt">"embedding_dim"</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span>
    <span class="nt">"pooling"</span><span class="p">:</span> <span class="s2">"cls_token"</span><span class="p">,</span>
    <span class="nt">"export"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
    <span class="nt">"dropout"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="nt">"attention_dropout"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="nt">"activation_dropout"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="nt">"ffn_embedding_dim"</span><span class="p">:</span> <span class="mi">3072</span><span class="p">,</span>
    <span class="nt">"num_encoder_layers"</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
    <span class="nt">"num_attention_heads"</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
    <span class="nt">"num_segments"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="nt">"use_position_embeddings"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
    <span class="nt">"offset_positions_by_padding"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
    <span class="nt">"apply_bert_init"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
    <span class="nt">"encoder_normalize_before"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
    <span class="nt">"activation_fn"</span><span class="p">:</span> <span class="s2">"relu"</span><span class="p">,</span>
    <span class="nt">"projection_dim"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">"max_seq_len"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="nt">"multilingual"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
    <span class="nt">"freeze_embeddings"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
    <span class="nt">"n_trans_layers_to_freeze"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="nt">"use_torchscript"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
    <span class="nt">"project_representation"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
    <span class="nt">"is_bidirectional"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
    <span class="nt">"stride"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="nt">"expressivity"</span><span class="p">:</span> <span class="mi">8</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">PyText</a></h1>
<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../train_your_first_model.html">Train your first model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../execute_your_first_model.html">Execute your first model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../visualize_your_model.html">Visualize Model Training with TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pytext_models_in_your_app.html">Use PyText models in your app</a></li>
<li class="toctree-l1"><a class="reference internal" href="../serving_models_in_production.html">Serve Models in Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../config_files.html">Config Files Explained</a></li>
<li class="toctree-l1"><a class="reference internal" href="../config_commands.html">Config Commands</a></li>
</ul>
<p class="caption"><span class="caption-text">Training More Advanced Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../atis_tutorial.html">Train Intent-Slot model on ATIS Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hierarchical_intent_slot_tutorial.html">Hierarchical intent and slot filling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../disjoint_multitask_tutorial.html">Multitask training with disjoint datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed_training_tutorial.html">Data Parallel Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../xlm_r.html">XLM-RoBERTa</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending PyText</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasource_tutorial.html">Custom Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensorizer.html">Custom Tensorizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dense.html">Using External Dense Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../create_new_model.html">Creating A New Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hacking_pytext.html">Hacking PyText</a></li>
</ul>
<p class="caption"><span class="caption-text">References</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="pytext.html">pytext</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="pytext.config.html">config</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.data.html">data</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.exporters.html">exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.loss.html">loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.metric_reporters.html">metric_reporters</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="pytext.models.html">models</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.optimizer.html">optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.task.html">task</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytext.trainers.html">trainers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules/pytext.html">pytext package</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="../index.html">Documentation overview</a><ul>
<li><a href="pytext.html">pytext</a><ul>
<li><a href="pytext.models.html">models</a><ul>
<li><a href="pytext.models.representations.html">representations</a><ul>
<li><a href="pytext.models.representations.sparse_transformer_sentence_encoder.html">sparse_transformer_sentence_encoder</a><ul>
<li>Previous: <a href="pytext.models.representations.sparse_transformer_sentence_encoder.html" title="previous chapter">sparse_transformer_sentence_encoder</a></li>
<li>Next: <a href="pytext.models.representations.stacked_bidirectional_rnn.html" title="next chapter">stacked_bidirectional_rnn</a></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="../search.html" class="search" method="get">
<input aria-labelledby="searchlabel" name="q" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
</div>
</div>
<div class="clearer"></div>
</div></div>