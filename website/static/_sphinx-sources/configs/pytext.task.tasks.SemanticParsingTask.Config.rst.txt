SemanticParsingTask.Config
==========================



**Component:** :class:`SemanticParsingTask  <pytext.task.tasks.SemanticParsingTask>`\ 


.. py:currentmodule:: pytext.task.tasks
.. py:class:: SemanticParsingTask.Config
  :noindex:

  **Bases:** :class:`NewTask.Config <pytext.task.new_task.NewTask.Config>`\ 

  

**All Attributes (including base classes)**

  **data**: :doc:`Data.Config <pytext.data.data.Data.Config>` = :doc:`Data.Config <pytext.data.data.Data.Config>`\ ()
    \ 

  **trainer**: :doc:`HogwildTrainer.Config <pytext.trainers.hogwild_trainer.HogwildTrainer.Config>` = :doc:`HogwildTrainer.Config <pytext.trainers.hogwild_trainer.HogwildTrainer.Config>`\ ()
    \ 

  **model**: :doc:`RNNGParser.Config <pytext.models.semantic_parsers.rnng.rnng_parser.RNNGParser.Config>` = :doc:`RNNGParser.Config <pytext.models.semantic_parsers.rnng.rnng_parser.RNNGParser.Config>`\ ()
    \ 

  **metric_reporter**: :doc:`CompositionalMetricReporter.Config <pytext.metric_reporters.compositional_metric_reporter.CompositionalMetricReporter.Config>` = :doc:`CompositionalMetricReporter.Config <pytext.metric_reporters.compositional_metric_reporter.CompositionalMetricReporter.Config>`\ ()
    \ 



**Default JSON**


.. code-block:: json


  {
      "data": {
          "Data": {
              "source": {
                  "TSVDataSource": {
                      "column_mapping": {},
                      "train_filename": null,
                      "test_filename": null,
                      "eval_filename": null,
                      "field_names": null,
                      "delimiter": "\t",
                      "quoted": false,
                      "drop_incomplete_rows": false
                  }
              },
              "batcher": {
                  "PoolingBatcher": {
                      "train_batch_size": 16,
                      "eval_batch_size": 16,
                      "test_batch_size": 16,
                      "pool_num_batches": 10000,
                      "num_shuffled_pools": 1
                  }
              },
              "sort_key": null,
              "in_memory": true
          }
      },
      "trainer": {
          "real_trainer": {
              "TaskTrainer": {
                  "epochs": 10,
                  "early_stop_after": 0,
                  "max_clip_norm": null,
                  "report_train_metrics": true,
                  "target_time_limit_seconds": null,
                  "do_eval": true,
                  "load_best_model_after_train": true,
                  "num_samples_to_log_progress": 1000,
                  "num_accumulated_batches": 1,
                  "num_batches_per_epoch": null,
                  "optimizer": {
                      "Adam": {
                          "lr": 0.001,
                          "weight_decay": 1e-05,
                          "eps": 1e-08
                      }
                  },
                  "scheduler": null,
                  "sparsifier": null,
                  "fp16_args": {
                      "FP16OptimizerFairseq": {
                          "init_loss_scale": 128,
                          "scale_window": null,
                          "scale_tolerance": 0.0,
                          "threshold_loss_scale": null,
                          "min_loss_scale": 0.0001
                      }
                  }
              }
          },
          "num_workers": 1
      },
      "model": {
          "version": 2,
          "lstm": {
              "load_path": null,
              "save_path": null,
              "freeze": false,
              "shared_module_key": null,
              "dropout": 0.4,
              "lstm_dim": 32,
              "num_layers": 1,
              "bidirectional": true,
              "pack_sequence": true
          },
          "ablation": {
              "use_buffer": true,
              "use_stack": true,
              "use_action": true,
              "use_last_open_NT_feature": false
          },
          "constraints": {
              "intent_slot_nesting": true,
              "ignore_loss_for_unsupported": false,
              "no_slots_inside_unsupported": true
          },
          "max_open_NT": 10,
          "dropout": 0.1,
          "beam_size": 1,
          "top_k": 1,
          "compositional_type": "blstm",
          "inputs": {
              "tokens": {
                  "is_input": true,
                  "column": "tokenized_text",
                  "tokenizer": {
                      "Tokenizer": {
                          "split_regex": "\\s+",
                          "lowercase": true
                      }
                  },
                  "add_bos_token": false,
                  "add_eos_token": false,
                  "use_eos_token_for_bos": false,
                  "max_seq_len": null,
                  "vocab": {
                      "build_from_data": true,
                      "size_from_data": 0,
                      "vocab_files": []
                  },
                  "vocab_file_delimiter": " "
              },
              "actions": {
                  "is_input": true,
                  "column": "seqlogical"
              }
          },
          "embedding": {
              "load_path": null,
              "save_path": null,
              "freeze": false,
              "shared_module_key": null,
              "embed_dim": 100,
              "embedding_init_strategy": "random",
              "embedding_init_range": null,
              "export_input_names": [
                  "tokens_vals"
              ],
              "pretrained_embeddings_path": "",
              "vocab_file": "",
              "vocab_size": 0,
              "vocab_from_train_data": true,
              "vocab_from_all_data": false,
              "vocab_from_pretrained_embeddings": false,
              "lowercase_tokens": true,
              "min_freq": 1,
              "mlp_layer_dims": [],
              "padding_idx": null,
              "cpu_only": false,
              "skip_header": true,
              "delimiter": " "
          }
      },
      "metric_reporter": {
          "output_path": "/tmp/test_out.txt",
          "pep_format": false,
          "text_column_name": "tokenized_text"
      }
  }