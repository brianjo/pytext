PureDocAttention.Config
=======================



**Component:** :class:`PureDocAttention  <pytext.models.representations.pure_doc_attention.PureDocAttention>`\ 


.. py:currentmodule:: pytext.models.representations.pure_doc_attention
.. py:class:: PureDocAttention.Config
  :noindex:

  **Bases:** :class:`RepresentationBase.Config <pytext.models.representations.representation_base.RepresentationBase.Config>`\ 

  

**All Attributes (including base classes)**

  **load_path**: Optional[str] = ``None``
    \ 

  **save_path**: Optional[str] = ``None``
    \ 

  **freeze**: bool = ``False``
    \ 

  **shared_module_key**: Optional[str] = ``None``
    \ 

  **dropout**: float = ``0.4``
    \ 

  **pooling**: Union[:doc:`SelfAttention.Config <pytext.models.representations.pooling.SelfAttention.Config>`, :doc:`MaxPool.Config <pytext.models.representations.pooling.MaxPool.Config>`, :doc:`MeanPool.Config <pytext.models.representations.pooling.MeanPool.Config>`, :doc:`NoPool.Config <pytext.models.representations.pooling.NoPool.Config>`, :doc:`BoundaryPool.Config <pytext.models.representations.pooling.BoundaryPool.Config>`] = :doc:`SelfAttention.Config <pytext.models.representations.pooling.SelfAttention.Config>`\ ()
    \ 

  **mlp_decoder**: Optional[:doc:`MLPDecoder.Config <pytext.models.decoders.mlp_decoder.MLPDecoder.Config>`] = ``None``
    \ 



**Default JSON**


.. code-block:: json


  {
      "load_path": null,
      "save_path": null,
      "freeze": false,
      "shared_module_key": null,
      "dropout": 0.4,
      "pooling": {
          "SelfAttention": {
              "attn_dimension": 64,
              "dropout": 0.4
          }
      },
      "mlp_decoder": null
  }