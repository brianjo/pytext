WordPieceTokenizer.Config
=========================



**Component:** :class:`WordPieceTokenizer  <pytext.data.tokenizers.tokenizer.WordPieceTokenizer>`\ 


.. py:currentmodule:: pytext.data.tokenizers.tokenizer
.. py:class:: WordPieceTokenizer.Config
  :noindex:

  **Bases:** :class:`ConfigBase <pytext.config.pytext_config.ConfigBase>`\ 

  

**All Attributes (including base classes)**

  **basic_tokenizer**: :doc:`BERTInitialTokenizer.Config <pytext.data.tokenizers.tokenizer.BERTInitialTokenizer.Config>` = :doc:`BERTInitialTokenizer.Config <pytext.data.tokenizers.tokenizer.BERTInitialTokenizer.Config>`\ ()
    \ 

  **wordpiece_vocab_path**: str = ``'/mnt/vol/nlp_technologies/bert/uncased_L-12_H-768_A-12/vocab.txt'``
    \ 



**Default JSON**


.. code-block:: json


  {
      "basic_tokenizer": {
          "split_regex": "\\s+",
          "lowercase": true
      },
      "wordpiece_vocab_path": "/mnt/vol/nlp_technologies/bert/uncased_L-12_H-768_A-12/vocab.txt"
  }