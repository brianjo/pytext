DocModel.Config
===============



**Component:** :class:`DocModel  <pytext.models.doc_model.DocModel>`\ 


.. py:currentmodule:: pytext.models.doc_model
.. py:class:: DocModel.Config
  :noindex:

  **Bases:** :class:`Model.Config <pytext.models.model.Model.Config>`\ 

  

**All Attributes (including base classes)**

  **inputs**: :doc:`ModelInput <pytext.models.doc_model.ModelInput>` = :doc:`ModelInput <pytext.models.doc_model.ModelInput>`\ ()
    \ 

  **embedding**: :doc:`WordEmbedding.Config <pytext.models.embeddings.word_embedding.WordEmbedding.Config>` = :doc:`WordEmbedding.Config <pytext.models.embeddings.word_embedding.WordEmbedding.Config>`\ ()
    \ 

  **representation**: Union[:doc:`PureDocAttention.Config <pytext.models.representations.pure_doc_attention.PureDocAttention.Config>`, :doc:`BiLSTMDocAttention.Config <pytext.models.representations.bilstm_doc_attention.BiLSTMDocAttention.Config>`, :doc:`DocNNRepresentation.Config <pytext.models.representations.docnn.DocNNRepresentation.Config>`, :doc:`DeepCNNRepresentation.Config <pytext.models.representations.deepcnn.DeepCNNRepresentation.Config>`] = :doc:`BiLSTMDocAttention.Config <pytext.models.representations.bilstm_doc_attention.BiLSTMDocAttention.Config>`\ ()
    \ 

  **decoder**: :doc:`MLPDecoder.Config <pytext.models.decoders.mlp_decoder.MLPDecoder.Config>` = :doc:`MLPDecoder.Config <pytext.models.decoders.mlp_decoder.MLPDecoder.Config>`\ ()
    \ 

  **output_layer**: :doc:`ClassificationOutputLayer.Config <pytext.models.output_layers.doc_classification_output_layer.ClassificationOutputLayer.Config>` = :doc:`ClassificationOutputLayer.Config <pytext.models.output_layers.doc_classification_output_layer.ClassificationOutputLayer.Config>`\ ()
    \ 



**Subclasses**
  - :class:`ByteTokensDocumentModel.Config <pytext.models.doc_model.ByteTokensDocumentModel.Config>`\ 
  - :class:`DocRegressionModel.Config <pytext.models.doc_model.DocRegressionModel.Config>`\ 
  - :class:`PersonalizedDocModel.Config <pytext.models.doc_model.PersonalizedDocModel.Config>`\ 
  - :class:`SeqNNModel.Config <pytext.models.seq_models.seqnn.SeqNNModel.Config>`\ 


**Default JSON**


.. code-block:: json


  {
      "inputs": {
          "tokens": {
              "is_input": true,
              "column": "text",
              "tokenizer": {
                  "Tokenizer": {
                      "split_regex": "\\s+",
                      "lowercase": true
                  }
              },
              "add_bos_token": false,
              "add_eos_token": false,
              "use_eos_token_for_bos": false,
              "max_seq_len": null,
              "vocab": {
                  "build_from_data": true,
                  "size_from_data": 0,
                  "vocab_files": []
              },
              "vocab_file_delimiter": " "
          },
          "dense": null,
          "labels": {
              "LabelTensorizer": {
                  "is_input": false,
                  "column": "label",
                  "allow_unknown": false,
                  "pad_in_vocab": false,
                  "label_vocab": null
              }
          }
      },
      "embedding": {
          "load_path": null,
          "save_path": null,
          "freeze": false,
          "shared_module_key": null,
          "embed_dim": 100,
          "embedding_init_strategy": "random",
          "embedding_init_range": null,
          "export_input_names": [
              "tokens_vals"
          ],
          "pretrained_embeddings_path": "",
          "vocab_file": "",
          "vocab_size": 0,
          "vocab_from_train_data": true,
          "vocab_from_all_data": false,
          "vocab_from_pretrained_embeddings": false,
          "lowercase_tokens": true,
          "min_freq": 1,
          "mlp_layer_dims": [],
          "padding_idx": null,
          "cpu_only": false,
          "skip_header": true,
          "delimiter": " "
      },
      "representation": {
          "BiLSTMDocAttention": {
              "load_path": null,
              "save_path": null,
              "freeze": false,
              "shared_module_key": null,
              "dropout": 0.4,
              "lstm": {
                  "load_path": null,
                  "save_path": null,
                  "freeze": false,
                  "shared_module_key": null,
                  "dropout": 0.4,
                  "lstm_dim": 32,
                  "num_layers": 1,
                  "bidirectional": true,
                  "pack_sequence": true
              },
              "pooling": {
                  "SelfAttention": {
                      "attn_dimension": 64,
                      "dropout": 0.4
                  }
              },
              "mlp_decoder": null
          }
      },
      "decoder": {
          "load_path": null,
          "save_path": null,
          "freeze": false,
          "shared_module_key": null,
          "hidden_dims": [],
          "out_dim": null,
          "layer_norm": false,
          "dropout": 0.0,
          "activation": "relu"
      },
      "output_layer": {
          "load_path": null,
          "save_path": null,
          "freeze": false,
          "shared_module_key": null,
          "loss": {
              "CrossEntropyLoss": {}
          },
          "label_weights": null
      }
  }