IntentSlotModelDecoder.Config
=============================



**Component:** :class:`IntentSlotModelDecoder  <pytext.models.decoders.intent_slot_model_decoder.IntentSlotModelDecoder>`\ 


.. py:currentmodule:: pytext.models.decoders.intent_slot_model_decoder
.. py:class:: IntentSlotModelDecoder.Config
  :noindex:

  **Bases:** :class:`DecoderBase.Config <pytext.models.decoders.decoder_base.DecoderBase.Config>`\ 

  
  Configuration class for `IntentSlotModelDecoder`.
  
  .. attribute:: use_doc_probs_in_word
  
     Whether to use intent probabilities
     for predicting slots.
  
     :type: bool
  

**All Attributes (including base classes)**

  **load_path**: Optional[str] = ``None``
    \ 

  **save_path**: Optional[str] = ``None``
    \ 

  **freeze**: bool = ``False``
    \ 

  **shared_module_key**: Optional[str] = ``None``
    \ 

  **use_doc_probs_in_word**: bool = ``False``
    \ 

  **doc_decoder**: :doc:`MLPDecoder.Config <pytext.models.decoders.mlp_decoder.MLPDecoder.Config>` = :doc:`MLPDecoder.Config <pytext.models.decoders.mlp_decoder.MLPDecoder.Config>`\ ()
    \ 

  **word_decoder**: :doc:`MLPDecoder.Config <pytext.models.decoders.mlp_decoder.MLPDecoder.Config>` = :doc:`MLPDecoder.Config <pytext.models.decoders.mlp_decoder.MLPDecoder.Config>`\ ()
    \ 



**Default JSON**


.. code-block:: json


  {
      "load_path": null,
      "save_path": null,
      "freeze": false,
      "shared_module_key": null,
      "use_doc_probs_in_word": false,
      "doc_decoder": {
          "load_path": null,
          "save_path": null,
          "freeze": false,
          "shared_module_key": null,
          "hidden_dims": [],
          "out_dim": null,
          "layer_norm": false,
          "dropout": 0.0,
          "activation": "relu"
      },
      "word_decoder": {
          "load_path": null,
          "save_path": null,
          "freeze": false,
          "shared_module_key": null,
          "hidden_dims": [],
          "out_dim": null,
          "layer_norm": false,
          "dropout": 0.0,
          "activation": "relu"
      }
  }