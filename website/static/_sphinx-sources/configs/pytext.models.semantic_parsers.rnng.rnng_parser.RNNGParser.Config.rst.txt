RNNGParser.Config
=================



**Component:** :class:`RNNGParser  <pytext.models.semantic_parsers.rnng.rnng_parser.RNNGParser>`\ 


.. py:currentmodule:: pytext.models.semantic_parsers.rnng.rnng_parser
.. py:class:: RNNGParser.Config
  :noindex:

  **Bases:** :class:`RNNGParserBase.Config <pytext.models.semantic_parsers.rnng.rnng_parser.RNNGParserBase.Config>`\ 

  

**All Attributes (including base classes)**

  **version**: int = ``2``
    \ 

  **lstm**: :doc:`BiLSTM.Config <pytext.models.representations.bilstm.BiLSTM.Config>` = :doc:`BiLSTM.Config <pytext.models.representations.bilstm.BiLSTM.Config>`\ ()
    \ 

  **ablation**: :doc:`AblationParams <pytext.models.semantic_parsers.rnng.rnng_parser.AblationParams>` = :doc:`AblationParams <pytext.models.semantic_parsers.rnng.rnng_parser.AblationParams>`\ ()
    \ 

  **constraints**: :doc:`RNNGConstraints <pytext.models.semantic_parsers.rnng.rnng_parser.RNNGConstraints>` = :doc:`RNNGConstraints <pytext.models.semantic_parsers.rnng.rnng_parser.RNNGConstraints>`\ ()
    \ 

  **max_open_NT**: int = ``10``
    \ 

  **dropout**: float = ``0.1``
    \ 

  **beam_size**: int = ``1``
    \ 

  **top_k**: int = ``1``
    \ 

  **compositional_type**: CompositionalType = ``<CompositionalType.BLSTM: 'blstm'>``
    \ 

  **inputs**: :doc:`ModelInput <pytext.models.semantic_parsers.rnng.rnng_parser.ModelInput>` = :doc:`ModelInput <pytext.models.semantic_parsers.rnng.rnng_parser.ModelInput>`\ ()
    \ 

  **embedding**: :doc:`WordEmbedding.Config <pytext.models.embeddings.word_embedding.WordEmbedding.Config>` = :doc:`WordEmbedding.Config <pytext.models.embeddings.word_embedding.WordEmbedding.Config>`\ ()
    \ 



**Default JSON**


.. code-block:: json


  {
      "version": 2,
      "lstm": {
          "load_path": null,
          "save_path": null,
          "freeze": false,
          "shared_module_key": null,
          "dropout": 0.4,
          "lstm_dim": 32,
          "num_layers": 1,
          "bidirectional": true,
          "pack_sequence": true
      },
      "ablation": {
          "use_buffer": true,
          "use_stack": true,
          "use_action": true,
          "use_last_open_NT_feature": false
      },
      "constraints": {
          "intent_slot_nesting": true,
          "ignore_loss_for_unsupported": false,
          "no_slots_inside_unsupported": true
      },
      "max_open_NT": 10,
      "dropout": 0.1,
      "beam_size": 1,
      "top_k": 1,
      "compositional_type": "blstm",
      "inputs": {
          "tokens": {
              "is_input": true,
              "column": "tokenized_text",
              "tokenizer": {
                  "Tokenizer": {
                      "split_regex": "\\s+",
                      "lowercase": true
                  }
              },
              "add_bos_token": false,
              "add_eos_token": false,
              "use_eos_token_for_bos": false,
              "max_seq_len": null,
              "vocab": {
                  "build_from_data": true,
                  "size_from_data": 0,
                  "vocab_files": []
              },
              "vocab_file_delimiter": " "
          },
          "actions": {
              "is_input": true,
              "column": "seqlogical"
          }
      },
      "embedding": {
          "load_path": null,
          "save_path": null,
          "freeze": false,
          "shared_module_key": null,
          "embed_dim": 100,
          "embedding_init_strategy": "random",
          "embedding_init_range": null,
          "export_input_names": [
              "tokens_vals"
          ],
          "pretrained_embeddings_path": "",
          "vocab_file": "",
          "vocab_size": 0,
          "vocab_from_train_data": true,
          "vocab_from_all_data": false,
          "vocab_from_pretrained_embeddings": false,
          "lowercase_tokens": true,
          "min_freq": 1,
          "mlp_layer_dims": [],
          "padding_idx": null,
          "cpu_only": false,
          "skip_header": true,
          "delimiter": " "
      }
  }