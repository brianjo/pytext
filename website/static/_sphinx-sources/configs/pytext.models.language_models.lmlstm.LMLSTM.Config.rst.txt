LMLSTM.Config
=============



**Component:** :class:`LMLSTM  <pytext.models.language_models.lmlstm.LMLSTM>`\ 


.. py:currentmodule:: pytext.models.language_models.lmlstm
.. py:class:: LMLSTM.Config
  :noindex:

  **Bases:** :class:`BaseModel.Config <pytext.models.model.BaseModel.Config>`\ 

  

**All Attributes (including base classes)**

  **inputs**: :doc:`ModelInput <pytext.models.language_models.lmlstm.ModelInput>` = :doc:`ModelInput <pytext.models.language_models.lmlstm.ModelInput>`\ ()
    \ 

  **embedding**: :doc:`WordEmbedding.Config <pytext.models.embeddings.word_embedding.WordEmbedding.Config>` = :doc:`WordEmbedding.Config <pytext.models.embeddings.word_embedding.WordEmbedding.Config>`\ ()
    \ 

  **representation**: Union[:doc:`BiLSTM.Config <pytext.models.representations.bilstm.BiLSTM.Config>`, :doc:`DeepCNNRepresentation.Config <pytext.models.representations.deepcnn.DeepCNNRepresentation.Config>`] = :doc:`BiLSTM.Config <pytext.models.representations.bilstm.BiLSTM.Config>`\ (bidirectional=\ ``False``\ )
    \ 

  **decoder**: Optional[:doc:`MLPDecoder.Config <pytext.models.decoders.mlp_decoder.MLPDecoder.Config>`] = :doc:`MLPDecoder.Config <pytext.models.decoders.mlp_decoder.MLPDecoder.Config>`\ ()
    \ 

  **output_layer**: :doc:`LMOutputLayer.Config <pytext.models.output_layers.lm_output_layer.LMOutputLayer.Config>` = :doc:`LMOutputLayer.Config <pytext.models.output_layers.lm_output_layer.LMOutputLayer.Config>`\ ()
    \ 

  **tied_weights**: bool = ``False``
    \ 

  **stateful**: bool = ``False``
    \ 

  **caffe2_format**: ExporterType = ``<ExporterType.PREDICTOR: 'predictor'>``
    \ 



**Default JSON**


.. code-block:: json


  {
      "inputs": {
          "tokens": {
              "is_input": true,
              "column": "text",
              "tokenizer": {
                  "Tokenizer": {
                      "split_regex": "\\s+",
                      "lowercase": true
                  }
              },
              "add_bos_token": true,
              "add_eos_token": true,
              "use_eos_token_for_bos": false,
              "max_seq_len": null,
              "vocab": {
                  "build_from_data": true,
                  "size_from_data": 0,
                  "vocab_files": []
              },
              "vocab_file_delimiter": " "
          }
      },
      "embedding": {
          "load_path": null,
          "save_path": null,
          "freeze": false,
          "shared_module_key": null,
          "embed_dim": 100,
          "embedding_init_strategy": "random",
          "embedding_init_range": null,
          "export_input_names": [
              "tokens_vals"
          ],
          "pretrained_embeddings_path": "",
          "vocab_file": "",
          "vocab_size": 0,
          "vocab_from_train_data": true,
          "vocab_from_all_data": false,
          "vocab_from_pretrained_embeddings": false,
          "lowercase_tokens": true,
          "min_freq": 1,
          "mlp_layer_dims": [],
          "padding_idx": null,
          "cpu_only": false,
          "skip_header": true,
          "delimiter": " "
      },
      "representation": {
          "BiLSTM": {
              "load_path": null,
              "save_path": null,
              "freeze": false,
              "shared_module_key": null,
              "dropout": 0.4,
              "lstm_dim": 32,
              "num_layers": 1,
              "bidirectional": false,
              "pack_sequence": true
          }
      },
      "decoder": {
          "load_path": null,
          "save_path": null,
          "freeze": false,
          "shared_module_key": null,
          "hidden_dims": [],
          "out_dim": null,
          "layer_norm": false,
          "dropout": 0.0,
          "activation": "relu"
      },
      "output_layer": {
          "load_path": null,
          "save_path": null,
          "freeze": false,
          "shared_module_key": null,
          "loss": {}
      },
      "tied_weights": false,
      "stateful": false,
      "caffe2_format": "predictor"
  }