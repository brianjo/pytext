TaskTrainer.Config
==================



**Component:** :class:`TaskTrainer  <pytext.trainers.trainer.TaskTrainer>`\ 


.. py:currentmodule:: pytext.trainers.trainer
.. py:class:: TaskTrainer.Config
  :noindex:

  **Bases:** :class:`Trainer.Config <pytext.trainers.trainer.Trainer.Config>`\ 

  Make mypy happy

**All Attributes (including base classes)**

  **epochs**: int = ``10``
    \ 

  **early_stop_after**: int = ``0``
    \ 

  **max_clip_norm**: Optional[float] = ``None``
    \ 

  **report_train_metrics**: bool = ``True``
    \ 

  **target_time_limit_seconds**: Optional[int] = ``None``
    \ 

  **do_eval**: bool = ``True``
    \ 

  **load_best_model_after_train**: bool = ``True``
    \ 

  **num_samples_to_log_progress**: int = ``1000``
    \ 

  **num_accumulated_batches**: int = ``1``
    \ 

  **num_batches_per_epoch**: Optional[int] = ``None``
    \ 

  **optimizer**: :doc:`Optimizer.Config <pytext.optimizer.optimizers.Optimizer.Config>` = :doc:`Adam.Config <pytext.optimizer.optimizers.Adam.Config>`\ ()
    \ 

  **scheduler**: Optional[:doc:`Scheduler.Config <pytext.optimizer.scheduler.Scheduler.Config>`] = ``None``
    \ 

  **sparsifier**: Optional[:doc:`Sparsifier.Config <pytext.optimizer.sparsifiers.sparsifier.Sparsifier.Config>`] = ``None``
    \ 

  **fp16_args**: :doc:`FP16Optimizer.Config <pytext.optimizer.fp16_optimizer.FP16Optimizer.Config>` = :doc:`FP16OptimizerFairseq.Config <pytext.optimizer.fp16_optimizer.FP16OptimizerFairseq.Config>`\ ()
    \ 



**Default JSON**


.. code-block:: json


  {
      "epochs": 10,
      "early_stop_after": 0,
      "max_clip_norm": null,
      "report_train_metrics": true,
      "target_time_limit_seconds": null,
      "do_eval": true,
      "load_best_model_after_train": true,
      "num_samples_to_log_progress": 1000,
      "num_accumulated_batches": 1,
      "num_batches_per_epoch": null,
      "optimizer": {
          "Adam": {
              "lr": 0.001,
              "weight_decay": 1e-05,
              "eps": 1e-08
          }
      },
      "scheduler": null,
      "sparsifier": null,
      "fp16_args": {
          "FP16OptimizerFairseq": {
              "init_loss_scale": 128,
              "scale_window": null,
              "scale_tolerance": 0.0,
              "threshold_loss_scale": null,
              "min_loss_scale": 0.0001
          }
      }
  }